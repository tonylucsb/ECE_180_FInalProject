{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "084d19d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "val_df = pd.read_csv(\"val.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9106340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "X_train = model.encode(train_df[\"query\"].tolist(), convert_to_tensor=True)\n",
    "X_val = model.encode(val_df[\"query\"].tolist(), convert_to_tensor=True)\n",
    "X_test = model.encode(test_df[\"query\"].tolist(), convert_to_tensor=True)\n",
    "\n",
    "X_train = X_train.unsqueeze(1)\n",
    "X_val   = X_val.unsqueeze(1)\n",
    "X_test  = X_test.unsqueeze(1)\n",
    "\n",
    "y_train = torch.tensor(train_df[\"carb\"].values, dtype=torch.float32).unsqueeze(1)\n",
    "y_val   = torch.tensor(val_df[\"carb\"].values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val, y_val), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d6fad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        return torch.sqrt(self.mse(yhat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd632a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size=384, hidden_size=64, activation='ReLU', num_layers=2, dropout=0.2, bidrectional=False):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        return self.fc(out[:, -1, :])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c510d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 35.5696\n",
      "           Val RMSE: 39.0734\n",
      "Epoch 2, Train Loss: 32.7550\n",
      "           Val RMSE: 37.3609\n",
      "Epoch 3, Train Loss: 31.4990\n",
      "           Val RMSE: 36.6106\n",
      "Epoch 4, Train Loss: 30.5363\n",
      "           Val RMSE: 36.1287\n",
      "Epoch 5, Train Loss: 30.2295\n",
      "           Val RMSE: 35.6607\n",
      "Epoch 6, Train Loss: 29.5854\n",
      "           Val RMSE: 35.4028\n",
      "Epoch 7, Train Loss: 29.2821\n",
      "           Val RMSE: 35.1561\n",
      "Epoch 8, Train Loss: 29.1696\n",
      "           Val RMSE: 35.0504\n",
      "Epoch 9, Train Loss: 28.6743\n",
      "           Val RMSE: 34.7867\n",
      "Epoch 10, Train Loss: 28.3511\n",
      "           Val RMSE: 34.8167\n",
      "Epoch 11, Train Loss: 28.6085\n",
      "           Val RMSE: 34.3892\n",
      "Epoch 12, Train Loss: 28.1759\n",
      "           Val RMSE: 34.3301\n",
      "Epoch 13, Train Loss: 28.4782\n",
      "           Val RMSE: 34.2525\n",
      "Epoch 14, Train Loss: 27.8323\n",
      "           Val RMSE: 34.2801\n",
      "Epoch 15, Train Loss: 28.0569\n",
      "           Val RMSE: 34.2781\n",
      "Epoch 16, Train Loss: 28.0413\n",
      "           Val RMSE: 34.1549\n",
      "Epoch 17, Train Loss: 27.9108\n",
      "           Val RMSE: 33.9168\n",
      "Epoch 18, Train Loss: 27.4729\n",
      "           Val RMSE: 33.8939\n",
      "Epoch 19, Train Loss: 27.6379\n",
      "           Val RMSE: 33.7776\n",
      "Epoch 20, Train Loss: 26.8694\n",
      "           Val RMSE: 33.7305\n",
      "Epoch 21, Train Loss: 27.4427\n",
      "           Val RMSE: 33.5155\n",
      "Epoch 22, Train Loss: 27.5076\n",
      "           Val RMSE: 33.5562\n",
      "Epoch 23, Train Loss: 27.4928\n",
      "           Val RMSE: 33.4220\n",
      "Epoch 24, Train Loss: 26.9473\n",
      "           Val RMSE: 33.3197\n",
      "Epoch 25, Train Loss: 27.1283\n",
      "           Val RMSE: 33.3286\n",
      "Epoch 26, Train Loss: 27.3459\n",
      "           Val RMSE: 33.2256\n",
      "Epoch 27, Train Loss: 27.0993\n",
      "           Val RMSE: 32.9219\n",
      "Epoch 28, Train Loss: 26.7885\n",
      "           Val RMSE: 33.0411\n",
      "Epoch 29, Train Loss: 26.7372\n",
      "           Val RMSE: 32.8795\n",
      "Epoch 30, Train Loss: 26.5943\n",
      "           Val RMSE: 32.7666\n",
      "Epoch 31, Train Loss: 26.5087\n",
      "           Val RMSE: 32.5699\n",
      "Epoch 32, Train Loss: 26.2170\n",
      "           Val RMSE: 32.6745\n",
      "Epoch 33, Train Loss: 26.2523\n",
      "           Val RMSE: 32.5654\n",
      "Epoch 34, Train Loss: 26.1403\n",
      "           Val RMSE: 32.5615\n",
      "Epoch 35, Train Loss: 25.8741\n",
      "           Val RMSE: 32.3849\n",
      "Epoch 36, Train Loss: 25.7922\n",
      "           Val RMSE: 32.3760\n",
      "Epoch 37, Train Loss: 25.7110\n",
      "           Val RMSE: 32.2730\n",
      "Epoch 38, Train Loss: 25.7771\n",
      "           Val RMSE: 32.1697\n",
      "Epoch 39, Train Loss: 25.7602\n",
      "           Val RMSE: 32.1235\n",
      "Epoch 40, Train Loss: 25.3501\n",
      "           Val RMSE: 32.2707\n",
      "Epoch 41, Train Loss: 25.4515\n",
      "           Val RMSE: 32.0982\n",
      "Epoch 42, Train Loss: 25.5516\n",
      "           Val RMSE: 31.9556\n",
      "Epoch 43, Train Loss: 25.3367\n",
      "           Val RMSE: 31.8594\n",
      "Epoch 44, Train Loss: 25.0442\n",
      "           Val RMSE: 31.8151\n",
      "Epoch 45, Train Loss: 25.1380\n",
      "           Val RMSE: 31.7793\n",
      "Epoch 46, Train Loss: 25.2279\n",
      "           Val RMSE: 31.7307\n",
      "Epoch 47, Train Loss: 25.1955\n",
      "           Val RMSE: 31.9251\n",
      "Epoch 48, Train Loss: 24.8193\n",
      "           Val RMSE: 31.7205\n",
      "Epoch 49, Train Loss: 24.9600\n",
      "           Val RMSE: 31.7677\n",
      "Epoch 50, Train Loss: 24.3629\n",
      "           Val RMSE: 31.4855\n",
      "Epoch 51, Train Loss: 24.9169\n",
      "           Val RMSE: 31.4697\n",
      "Epoch 52, Train Loss: 24.6520\n",
      "           Val RMSE: 31.5074\n",
      "Epoch 53, Train Loss: 24.5853\n",
      "           Val RMSE: 31.3862\n",
      "Epoch 54, Train Loss: 24.6031\n",
      "           Val RMSE: 31.2235\n",
      "Epoch 55, Train Loss: 24.2869\n",
      "           Val RMSE: 31.3783\n",
      "Epoch 56, Train Loss: 24.3319\n",
      "           Val RMSE: 31.2936\n",
      "Epoch 57, Train Loss: 24.2683\n",
      "           Val RMSE: 31.2423\n",
      "Epoch 58, Train Loss: 24.6595\n",
      "           Val RMSE: 31.0141\n",
      "Epoch 59, Train Loss: 24.3356\n",
      "           Val RMSE: 31.1679\n",
      "Epoch 60, Train Loss: 24.2521\n",
      "           Val RMSE: 31.0874\n",
      "Epoch 61, Train Loss: 24.2397\n",
      "           Val RMSE: 30.8275\n",
      "Epoch 62, Train Loss: 24.0911\n",
      "           Val RMSE: 30.9377\n",
      "Epoch 63, Train Loss: 23.7634\n",
      "           Val RMSE: 30.8053\n",
      "Epoch 64, Train Loss: 24.0647\n",
      "           Val RMSE: 30.6524\n",
      "Epoch 65, Train Loss: 23.8336\n",
      "           Val RMSE: 30.6473\n",
      "Epoch 66, Train Loss: 23.3958\n",
      "           Val RMSE: 30.8261\n",
      "Epoch 67, Train Loss: 23.5225\n",
      "           Val RMSE: 30.7566\n",
      "Epoch 68, Train Loss: 23.4408\n",
      "           Val RMSE: 30.6799\n",
      "Epoch 69, Train Loss: 23.7294\n",
      "           Val RMSE: 30.4517\n",
      "Epoch 70, Train Loss: 23.6455\n",
      "           Val RMSE: 30.4415\n",
      "Epoch 71, Train Loss: 22.8685\n",
      "           Val RMSE: 30.3814\n",
      "Epoch 72, Train Loss: 23.1286\n",
      "           Val RMSE: 30.5866\n",
      "Epoch 73, Train Loss: 23.0732\n",
      "           Val RMSE: 30.2202\n",
      "Epoch 74, Train Loss: 23.1447\n",
      "           Val RMSE: 30.3151\n",
      "Epoch 75, Train Loss: 22.8100\n",
      "           Val RMSE: 30.3730\n",
      "Epoch 76, Train Loss: 22.6583\n",
      "           Val RMSE: 30.2912\n",
      "Epoch 77, Train Loss: 22.4992\n",
      "           Val RMSE: 30.3795\n",
      "Epoch 78, Train Loss: 22.4857\n",
      "           Val RMSE: 30.1429\n",
      "Epoch 79, Train Loss: 22.7619\n",
      "           Val RMSE: 30.2379\n",
      "Epoch 80, Train Loss: 22.4816\n",
      "           Val RMSE: 30.0386\n",
      "Epoch 81, Train Loss: 22.6311\n",
      "           Val RMSE: 30.0595\n",
      "Epoch 82, Train Loss: 22.7602\n",
      "           Val RMSE: 30.1729\n",
      "Epoch 83, Train Loss: 22.5949\n",
      "           Val RMSE: 30.0204\n",
      "Epoch 84, Train Loss: 22.4541\n",
      "           Val RMSE: 29.9429\n",
      "Epoch 85, Train Loss: 22.3911\n",
      "           Val RMSE: 30.0102\n",
      "Epoch 86, Train Loss: 22.4137\n",
      "           Val RMSE: 29.8866\n",
      "Epoch 87, Train Loss: 21.9603\n",
      "           Val RMSE: 30.2096\n",
      "Epoch 88, Train Loss: 21.8985\n",
      "           Val RMSE: 29.7409\n",
      "Epoch 89, Train Loss: 22.1870\n",
      "           Val RMSE: 29.6948\n",
      "Epoch 90, Train Loss: 21.7209\n",
      "           Val RMSE: 29.5720\n",
      "Epoch 91, Train Loss: 21.9200\n",
      "           Val RMSE: 29.6321\n",
      "Epoch 92, Train Loss: 21.8193\n",
      "           Val RMSE: 29.4105\n",
      "Epoch 93, Train Loss: 21.5744\n",
      "           Val RMSE: 29.5080\n",
      "Epoch 94, Train Loss: 21.7496\n",
      "           Val RMSE: 29.4254\n",
      "Epoch 95, Train Loss: 21.7330\n",
      "           Val RMSE: 29.2765\n",
      "Epoch 96, Train Loss: 21.1460\n",
      "           Val RMSE: 29.2671\n",
      "Epoch 97, Train Loss: 21.4045\n",
      "           Val RMSE: 29.2437\n",
      "Epoch 98, Train Loss: 21.2144\n",
      "           Val RMSE: 29.2850\n",
      "Epoch 99, Train Loss: 21.1385\n",
      "           Val RMSE: 29.1835\n",
      "Epoch 100, Train Loss: 21.0188\n",
      "           Val RMSE: 29.2369\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_deacy=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7e61155",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test).squeeze().numpy()\n",
    "\n",
    "# Add prediction column and save\n",
    "test_df[\"carb\"] = preds\n",
    "test_df.to_csv(\"RNNtesting.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
